# coding: utf-8'''Receive request from queue ,then reverse,send result to queue;'''import sysfrom os import pathsys.path.append(path.split(path.split(path.abspath(__file__))[0])[0])import osimport signalimport timefrom jinja2 import Templatefrom collections import defaultdictfrom threading import Thread# sqlalchemyfrom Pub.ORM import *from Pub.RabbitMQ import *# rabbitmqtemplateContent="""# 溯源报告报告ID： {{ id }}|项目|值|| ------  | ----------- || 发起时间 |  {{ start_time }} || 完成时间 | {{ finish_time }} || 洋葱地址 | {{ tor_address }} || 网站名称 | {{ site_name }} || IP地址  | {{ ip_address }} || 国家地区 | {{ country }} || 服务类型 | {{ service_type }} |# 详细信息## 探测路径参数：{{ client_ip }} ->{% for i in path %}{{ i }} -> {% endfor %}{{ ip_address }}接收任务客户端:|项目|值|| ---- | --- |{% for i in clients %}| Client {{ loop.index }} | {{ i }} |{% endfor %}Stream Id信息:| IP | Circ ID |Stream ID| Time || ---- | --- | --- | --- |{% for i in stream_id %}| {{ path[loop.index] }} | {{ circ_id[loop.index] }} | {{ stream_id[loop.index] }} | {{ times[loop.index] }} |{% endfor %}## 目标IP详情{{ details }}"""rabbitMQ=RabbitMQWrapper()try:    channel = rabbitMQ.getChannel()    reverseResultQueue = config["reverseResultQueue"]    reverseRequestQueue = config["reverseRequestQueue"]    channel.queue_declare(queue = reverseResultQueue)    channel.queue_declare(queue = reverseRequestQueue)except:    print("error accour in connection to rabbitMQ")Session = sessionmaker(bind = engine)'''class ConnectionLink'''query = ("select my_ip,next_ip,next_port,prev_circ_id,next_circ_id,direction,stream_id,is_origin from net "         "where time between %s and %s ")def exiter(_1, _2):    os._exit(0)def readFromDB(start_time , end_time):    '''    use my_ip as key    use prev_circ as second key (accelerate search whether prev_circ is there)    start_time:long(time stamp)    end_time:long    rtype dict(),dict() --{"my_ip":{"prev_circ_id":link}},{...}    '''    relay = defaultdict(dict)    origin = defaultdict(dict)    session = Session()    for instance in session.query(Link).filter(            sqlalchemy.and_(Link.datetime >= start_time, Link.datetime <= end_time)).order_by(Link.id):        # for instance in session.query(Link).order_by(Link.id):        if (instance.is_origin):            origin[instance.my_ip][instance.prev_circ_id] = instance        else:            relay[instance.my_ip][instance.prev_circ_id] = instance    return origin, relayorigins, relays = defaultdict(dict), defaultdict(dict)  # global var#     return Nonedef searchNext(p, relays,depth=0):    # todo using direction to estimate whether this relay is right    # p:type link  --the previous one    # relays:type dict {"my_ip":{"prev_circ_id":link}} --the relay dict    # return list(link)  --the list from p {type:link} to end looks like [p1,p2,p3]    if(p.next_ip=='0.0.0.0'): #join        #search next relay by next_circ_id        session=Session()        l=session.query(Link).filter_by(prev_circ_id=p.next_circ_id).all()        for i in l:#all            t=searchNext(i,relays,depth+1)            if (t is not None and len(t)==3):                t.insert(0, p)                #todo change this to a list owing to prev_circ_id is so small                return t                # Don't need to return if failed        return None    elif (p.next_ip in relays):        nls = relays[p.next_ip]        #         print(nls)        if (p.next_circ_id in nls):  # prev_relay.next_circ_id equals to the next one's prev_circ_id            t = searchNext(nls[p.next_circ_id], relays,depth = depth+1)            if (t is not None):                t.insert(0, p)                return t            else:                # The last one is nls[p.next_circ_id]                return [p, nls[p.next_circ_id]]    return Nonedef linkAll(start_time = None, end_time = time.time()):    '''    link all relays order by url_id    :return:reversedLinks: dict("url_id":list(list(link))) {id:[[p1,p2,p3],[p1,p3,p4,p5]]}    '''    if (start_time is None):        # default -30 minutes        start_time = end_time - 30 * 60    end_time = end_time + 1    reversedLinks = defaultdict(list)    origins, relays = readFromDB(start_time, end_time)    #     print(origins,relays)    for oStr in origins:  # though all the origin.Origins types {"my_ip":{"prev_circ_id":link}}        o = origins[oStr]  # O types {"prev_circ_id":link}        for prev_circ_id in o:  # all the next ip            p = o[prev_circ_id]  # p types Link            t = searchNext(p, relays,0)            if (t != None and len(t) == 7):                reversedLinks[p.url_id].append(t)    return reversedLinksdef saveLinkedRelays(reversedLinks):    '''    :reversedLinks:dict("url_id":list(list(link))) {id:[[p1,p2,p3],[p1,p3,p4,p5]]}    :return: urls,connectionLinks    save connectionlinks into database    '''    session = Session()    urls = []    connectionLinks = []    for u in reversedLinks:        url = session.query(Url).filter_by(url_id = u).first()        if(url is not None and url.server_ip is not None and len(url.server_ip)>0):            continue        print(url)        # urls.append()        print(reversedLinks[u][0][-1].next_ip)        print(type(url))        url.server_ip = reversedLinks[u][0][-1].next_ip        urls.append(url)        for linkList in reversedLinks[u]:            c = session.query(ConnectionLink).filter_by(request_id = linkList[0].request_id).first()            if c is None:                c = ConnectionLink(request_id = linkList[0].request_id, url_id = linkList[0].url_id,                    datetime = linkList[0].datetime                    , client = linkList[0].my_ip, server = linkList[-1].next_ip,                    link1 = linkList[0].id, link2 = linkList[1].id, link3 = linkList[2].id, linkmid = linkList[3].id,                    link4 = linkList[4].id, link5 = linkList[5].id, link6 = linkList[6].id)            else:                c.url_id = linkList[0].url_id                c.datetime = linkList[0].datetime                c.client = linkList[0].my_ip                c.server = linkList[-1].next_ip                c.link1 = linkList[0].id                c.link2 = linkList[1].id                c.link3 = linkList[2].id                c.linkmid = linkList[3].id                c.link4 = linkList[4].id                c.link5 = linkList[5].id                c.link6 = linkList[6].id            connectionLinks.append(c)    print(urls)    session.add_all(urls)    session.add_all(connectionLinks)    session.commit()    return urls, connectionLinksdef transformToMD(body):    template = Template(templateContent)    # info = json.loads(body)    info = body    info["country"] = "局域网"    outfileInfor = template.render(**info)    return outfileInfordef transformConnectionLink(connectionLinks):    '''    {"url":"xxx","md":"xxx"}    :param connectionLinks:    :return:    '''    session=Session()    for connectionLink in connectionLinks:        d={"id":connectionLink.request_id,           "finish_time":time.strftime("%Y年%m月%d日 %H:%M:%S",time.localtime(float(connectionLink.datetime)))           ,"ip_address":connectionLink.server,"server_type":"normal",           "client_ip":connectionLink.client,"site_name":"unknown","details":"""## Nmap服务器扫描### 端口扫描结果| 端口号 | 结果  | 描述 || ----- | ---: | ---- || 22 | open | SSH || 80 | open | web || 9011 | open | unknown |### 服务器探测服务器类型： Linux服务器fingerprint：ABA4BAB4694A7347201B4B4BCC62D867C2465A97"""}        path=[]#mid        circ_id=[]#        stream_id=[]        times=[]        for i in ["link"+str(c) for c in range(1,7)]:            linkId=connectionLink.__getattribute__(i)            link=session.query(Link).filter_by(id=linkId).first()            if(link is None):                print("----")                break            else:                circ_id.append(link.next_circ_id)                path.append(link.my_ip)                stream_id.append(link.stream_id)                t=time.strftime("%Y年%m月%d日 %H:%M:%S",time.localtime(float(link.datetime)))                times.append(t)        #Remove first ip and add the last server ip        path.append(link.next_ip)        path=path[1:]        d["path"]=path        d["stream_id"]=stream_id        d["circ_id"]=circ_id        d["times"]=times        url=session.query(Url).filter_by(url_id=connectionLink.url_id).first()        d["tor_address"]=url.url if url else ""        d["start_time"]=times[0]        MD=transformToMD(d)        body={"url":d["tor_address"],"md":MD}        print("send MD")        if(channel.is_closed):            channel=rabbitMQ.getChannel()            channel.queue_declare(queue = "clientEnd")        channel.basic_publish(exchange = "",routing_key = "clientEnd",body=json.dumps(body))    session.close()def test():    session = Session()    session.add(Url(url_id = 2, url = "www.baidu.com"))    list = []    list.append(Link(request_id = 1, url_id = 2, datetime = time.time(),        my_ip="10.0.0.0",next_ip = "10.0.0.1", prev_circ_id = 2 ,next_circ_id = 2,        next_port = 1900, direction = 1, stream_id = 0, is_origin = 1))    list.append(Link(datetime = time.time(),        my_ip = "10.0.0.1", next_ip = "10.0.0.2", prev_circ_id = 2, next_circ_id = 4,        next_port = 1900, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        my_ip = "10.0.0.2", next_ip = "10.0.0.3", prev_circ_id = 4, next_circ_id = 5,        next_port = 1900, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        my_ip = "10.0.0.3", next_ip = "0.0.0.0", prev_circ_id = 5, next_circ_id = 7,        next_port = 900, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        my_ip = "10.0.0.9", next_ip = "10.0.0.10", prev_circ_id = 7, next_circ_id = 10,        next_port = 190, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        my_ip = "10.0.0.10", next_ip = "10.0.0.11", prev_circ_id = 10, next_circ_id = 20,        next_port = 1900, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        my_ip = "10.0.0.11", next_ip = "10.0.0.210", prev_circ_id = 20, next_circ_id = 21,        next_port = 900, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        prev_circ_id = 9, next_circ_id = 8, my_ip = "10.0.0.4", next_ip = "10.0.0.5",        next_port = 190, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        prev_circ_id = 8, next_circ_id = 8, my_ip = "10.0.0.4", next_ip = "10.0.0.5",        next_port = 190, direction = 1, stream_id = 0, is_origin = 0))    list.append(Link(datetime = time.time(),        prev_circ_id = 1, next_circ_id = 10, my_ip = "10.0.0.4", next_ip = "10.0.0.5",        next_port = 190, direction = 1, stream_id = 0, is_origin = 0))    session.add_all(list)    session.commit()    reverseThread()    returndef testSQL():    session = Session()    url = Url(url_id = 4, server_ip = "123", url = "sdf")    session.add(url)    session.commit()    # session=Session()    # url=session.query(Url).filter_by(url_id=2).first()    # url.values(sever_ip="1231231")    #    # print(url)    # session.add(url)    # session.commit()def waitForReverseRequest(ch, method, properties, body):    task = json.loads(body)    # url = Url(url)    # todo fix this task    channel.basic_ack(delivery_tag = method.delivery_tag)def reverseThread():    while (True):        reversedLists = linkAll()        # try:        urls, connectionLinks = saveLinkedRelays(reversedLinks = reversedLists)        transformConnectionLink(connectionLinks)        # except:        #     print("error accour in saveLink or publish to queue")        time.sleep(0.5)if __name__ == "__main__":    test()    # testSQL()    # signal.signal(signal.SIGINT, exiter)    # t = Thread(target = reverseThread)    # t.start()    # channel.basic_qos(prefetch_count = 1)    # channel.basic_consume(waitForReverseRequest, reverseRequestQueue, no_ack = False)    # channel.start_consuming()